This is about the code repository for the paper "MKPL: Multi-dimensional Knowledge-embedded Prompt Learning for Few-shot Robust Malware Family Inference." Next, I will provide a detailed description of each folder's contents.

bert-base-uncased, bert-large-uncased, roberta-base, roberta-large: These folders contain the original parameters of the large models and modified vocabularies, among other things. You need to download these large language models.
prompt_learning: This is the core code for prompt learning training and inference.
finetune: This folder contains the code for fine-tuning training.
prompt_paraphrase: This includes content related to the automated generation of templates.
prompt_score: This is used for scoring the templates.
data: This folder contains various data after preprocessing.
robust_test: This folder is for robustness experiments.
compare_LLM: This folder contains the code for comparison experiments with different large language models.
bert_mlm_nsp: This contains the code related to the re-training on API data.