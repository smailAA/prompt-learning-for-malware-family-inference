# 提示学习训练和模型评估

import os
from transformers import BertConfig, BertModel, BertTokenizer, BertForMaskedLM
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score


class ModelConfig:
    def __init__(self):
        self.project_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

        # ========== api 数据集相关配置
        self.dataset_dir = os.path.join(self.project_dir, 'data', 'type4_classification')
        self.pretrained_model_dir = os.path.join(self.project_dir, "bert-base-uncased")
        self.train_file_path = os.path.join(self.dataset_dir, 'train_data_texts.txt')
        self.val_file_path = os.path.join(self.dataset_dir, 'dev_data_texts.txt')
        self.test_file_path = os.path.join(self.dataset_dir, 'test_data_texts.txt')
        self.train_label_path = os.path.join(self.dataset_dir, 'train_data_labels.csv')
        self.val_label_path = os.path.join(self.dataset_dir, 'dev_data_labels.csv')
        self.test_label_path = os.path.join(self.dataset_dir, 'test_data_labels.csv')
        self.data_name = 'prompt'

        # 如果需要切换数据集，只需要更改上面的配置即可

        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model_save_dir = os.path.join(self.project_dir, 'cache', 'type4', 'bert_start')
        self.logs_save_dir = os.path.join(self.project_dir, 'logs')
        self.model_save_path = os.path.join(self.model_save_dir, f'type4_loss_{self.data_name}.bin')
        self.model_acc_save_path = os.path.join(self.model_save_dir, f'type4_acc_{self.data_name}.bin')
        self.log_file_name = os.path.join(self.logs_save_dir, 'single_template_score.txt')
        self.writer = SummaryWriter(f"runs/{self.data_name}")
        self.is_sample_shuffle = True
        self.use_embedding_weight = True
        self.batch_size = 16
        self.max_sen_len = 512  # 为None时则采用每个batch中最长的样本对该batch中的样本进行padding
        self.pad_index = 0
        self.random_state = 2022
        self.learning_rate = 4e-5
        self.weight_decay = 0.1
        self.masked_rate = 0.15
        self.masked_token_rate = 0.8
        self.masked_token_unchanged_rate = 0.5
        self.MASK_POS = None  # 提示模版中 [mask] 位置,需要通过计算后更改
        self.prefix = None  # 提示模版，人为更改

        # tokenizer
        self.tokenizer = BertTokenizer.from_pretrained(self.pretrained_model_dir, local_files_only=True)

        self.use_torch_multi_head = False  # False表示使用model/BasicBert/MyTransformer中的多头实现
        self.epochs = 1
        self.model_val_per_epoch = 1

        if not os.path.exists(self.model_save_dir):
            os.makedirs(self.model_save_dir)
        bert_config_path = os.path.join(self.pretrained_model_dir, "config.json")
        bert_config = BertConfig.from_json_file(bert_config_path)
        for key, value in bert_config.__dict__.items():
            self.__dict__[key] = value


# Pandas显示选项，以便在打印数据框时显示所有列和行。
pd.options.display.max_columns = None
pd.options.display.max_rows = None


# 查找一下mask的位置
def find_mask_position(input_text, tokenizer):
    # 将文本内容编码成模型输入所需的格式，包括 token ID、token类型ID 和 attention mask。
    encode_dict = tokenizer.encode_plus(input_text,
                                        max_length=model_config.max_sen_len,
                                        padding="max_length",
                                        truncation=True)

    input_id = encode_dict['input_ids']
    mask_position = None
    for i, token in enumerate(input_id):
        if token == 103:
            mask_position = i

    if mask_position:

        print(f'mask position:{mask_position}')
        return mask_position
    else:
        print(f'mask position not found')
        return None


def define_labels():
    labels = {'trojan': 0,
              'backdoor': 1,
              'downloader': 2,
              'worms': 3,
              'spyware': 4,
              'adware': 5,
              'dropper': 6,
              'virus': 7
              }
    label_ids = {}
    tokenizer = BertTokenizer.from_pretrained(model_config.pretrained_model_dir, local_files_only=True)
    for label, index in labels.items():
        label_ids[label] = tokenizer.convert_tokens_to_ids(label)
    return label_ids


class Bert_Model(nn.Module):
    def __init__(self, bert_path):
        super(Bert_Model, self).__init__()
        self.bert = BertForMaskedLM.from_pretrained(bert_path)  # 加载预训练模型权重

    def forward(self, input_ids, attention_mask, token_type_ids):
        outputs = self.bert(input_ids, attention_mask,
                            token_type_ids)  # masked LM 输出的是 mask的值 对应的ids的概率 ，输出 会是词表大小，里面是概率
        logit = outputs[0]  # 包含预测的 token 的概率分布

        return logit


# 构建数据集


class MyDataSet(Dataset):
    # 输入句子，掩码，类型，标签
    def __init__(self, sen, mask, typ, label):
        super(MyDataSet, self).__init__()
        self.sen = torch.tensor(sen, dtype=torch.long)
        self.mask = torch.tensor(mask, dtype=torch.long)
        self.typ = torch.tensor(typ, dtype=torch.long)
        self.label = torch.tensor(label, dtype=torch.long)

    def __len__(self):
        return self.sen.shape[0]

    def __getitem__(self, idx):
        return self.sen[idx], self.mask[idx], self.typ[idx], self.label[idx]


# load  data

# 读取数据并组合成数组
def combine_files(API_path, label_path):
    # 标签与数字的对应关系
    label_dict = {'trojan': 0, 'backdoor': 1, 'downloader': 2, 'worms': 3, 'spyware': 4, 'adware': 5, 'dropper': 6,
                  'virus': 7}

    # 初始化空列表，用于存储text和label
    texts = []
    labels = []

    # 读取第一个文件
    with open(API_path, 'r') as API_file:
        for line in API_file:
            # 去除每行末尾的换行符
            line = line.rstrip()
            # 将处理后的行添加到texts列表
            texts.append(line)

    # 读取第二个文件
    with open(label_path, 'r') as label_file:
        for line in label_file:
            # 去除每行末尾的换行符
            line = line.rstrip()
            # 使用标签字典将标签转换为数字，并将处理后的行添加到labels列表
            label = label_dict.get(line)
            if label is not None:
                labels.append(label)
            else:
                print(f"Error: Label '{line}' not found in the dictionary.")
                return None

    # 确保两个列表长度一致
    if len(texts) == len(labels):

        return texts, labels
    else:
        print("Error: Lengths of texts and labels do not match.")
        return None


# get the data and label

def ProcessData(API_path, label_path, prefix):
    x_train, y_train = combine_files(API_path, label_path)
    # x_train,x_test,y_train,y_test=train_test_split(StrongData,StrongLabel,test_size=0.3, random_state=42)

    text = []
    Inputid = []
    Labelid = []
    typeid = []
    attenmask = []
    label_ids = define_labels()
    MASK_POS = model_config.MASK_POS

    for i in range(len(x_train)):
        # 在每个句子中的每个句号后添加[SEP]
        text_ = prefix + x_train[i]
        # 将文本内容编码成模型输入所需的格式，包括 token ID、token类型ID 和 attention mask。
        encode_dict = model_config.tokenizer.encode_plus(text_,
                                                         max_length=model_config.max_sen_len,
                                                         padding="max_length",
                                                         truncation=True)

        input_ids = encode_dict["input_ids"]
        type_ids = encode_dict["token_type_ids"]
        atten_mask = encode_dict["attention_mask"]
        # 对列表进行复制
        labelid, inputid = input_ids[:], input_ids[:]

        if y_train[i] == 0:
            labelid[MASK_POS] = label_ids['trojan']
            continue
        elif y_train[i] == 1:
            labelid[MASK_POS] = label_ids['backdoor']
            continue
        elif y_train[i] == 2:
            labelid[MASK_POS] = label_ids['downloader']
        elif y_train[i] == 3:
            labelid[MASK_POS] = label_ids['worms']

        elif y_train[i] == 4:
            labelid[MASK_POS] = label_ids['spyware']
            continue
        elif y_train[i] == 5:
            labelid[MASK_POS] = label_ids['adware']

        elif y_train[i] == 6:
            labelid[MASK_POS] = label_ids['dropper']
            continue
        elif y_train[i] == 7:
            labelid[MASK_POS] = label_ids['virus']

        # 除了mask对应的位置是病毒家族的token id，其他都是-1
        labelid[:MASK_POS] = [-1] * len(labelid[:MASK_POS])
        labelid[MASK_POS + 1:] = [-1] * len(labelid[MASK_POS + 1:])
        inputid[MASK_POS] = model_config.tokenizer.mask_token_id

        text.append(text_)
        Labelid.append(labelid)
        Inputid.append(inputid)
        typeid.append(type_ids)
        attenmask.append(atten_mask)

    return Inputid, Labelid, typeid, attenmask


def print_and_log(message, file):
    print(message)
    print('正在写入日志文件：')
    with open(file, 'a') as log_file:
        log_file.write(message + '\n')


# 读取模版
def load_single_template(file_name):
    templates = []
    with open(file_name, 'r') as file:
        for line in file:
            line = line.strip()
            templates.append(line)

    return templates


def evaluate_model_performance(config):
    # 不训练，直接评估模型在测试集上的性能。
    model = Bert_Model(bert_path=config.pretrained_model_dir)

    # 查看本地是否存在相关模型（否则无法评估）

    if os.path.exists(config.model_save_path):
        model.load_state_dict(torch.load(config.model_save_path))
        print("从以下路径加载模型参数：", config.model_save_path)
    else:
        print("未找到保存的参数。无法进行评估测试")

    model = model.to(config.device)
    # 模型评估
    model.eval()

    Inputid_test, Labelid_test, typeids_test, inputnmask_test = ProcessData(config.test_file_path,
                                                                            config.test_label_path, config.prefix)

    test_dataset = DataLoader(MyDataSet(Inputid_test, inputnmask_test, typeids_test, Labelid_test), config.batch_size,
                              True)

    predictions = []
    true_labels = []
    MASK_POS = config.MASK_POS
    with torch.no_grad():
        for input_ids, attention_mask, type_ids, test_labels_processed in test_dataset:
            input_ids, attention_mask, type_ids, test_labels_processed = input_ids.to(config.device), \
                                                                         attention_mask.to(config.device), \
                                                                         type_ids.to(config.device), \
                                                                         test_labels_processed.to(config.device)
            outputs = model(input_ids, attention_mask, type_ids)
            predicted_label = torch.argmax(outputs[:, MASK_POS, :], dim=1)
            predictions.extend(predicted_label.cpu().numpy())
            true_labels.extend(test_labels_processed[:, MASK_POS].cpu().numpy())

    # 计算指标

    accuracy = accuracy_score(true_labels, predictions)
    precision = precision_score(true_labels, predictions, average='weighted')
    recall = recall_score(true_labels, predictions, average='weighted')
    f1 = f1_score(true_labels, predictions, average='weighted')

    message = (
        f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, '
        f'recall: {recall:.4f}, f1: {f1:.4f}, '
    )
    print(message)

    return accuracy, precision, recall, f1


# 对模版中的每个句子，调用模型评估函数，看在原始BERT上的性能。
def template_score(templates, config):
    for prefix in templates:
        prefix1 = prefix.replace('.', '. [SEP]')
        config.prefix = prefix1
        config.MASK_POS = find_mask_position(config.prefix, config.tokenizer)
        accuracy, precision, recall, f1 = evaluate_model_performance(config)
        message = (
            f'template:{prefix},'
            f'accuracy: {accuracy:.4f}, precision: {precision:.4f}, '
            f'recall: {recall:.4f}, f1: {f1:.4f}, '
        )
        print_and_log(message, model_config.log_file_name)


model_config = ModelConfig()

if __name__ == '__main__':
    template_file = 'single_template.txt'
    templates = load_single_template(template_file)
    template_score(templates, model_config)
